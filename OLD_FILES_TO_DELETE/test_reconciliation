"""
Test the complete pipeline with reconciliation
"""

from captioner import HighPerformanceBatchWorker
from captioner import OptimizedSubtitleFormatter


def test_complete_pipeline():
    """Test complete pipeline from Whisper result to VTT"""
    
    # Simulate a realistic Whisper result
    whisper_result = {
        'text': "In this video we're going to go over screen space reflections which is a complex topic that deserves a little bit more time for discussion. Screen space reflections allow you to calculate reflections from the scene in real time without needing to use reflection probes which we cover in the next module. This is a very intense effect so reflection probes are the more performant option but screen space reflections are an option if you're targeting very high-end devices.",
        'chunks': [
            # Simulate Whisper skipping some words in word-level output
            {'words': [{'word': 'In', 'start': 0.0, 'end': 0.2}]},
            {'words': [{'word': 'this', 'start': 0.2, 'end': 0.4}]},
            {'words': [{'word': 'video', 'start': 0.4, 'end': 0.7}]},
            {'words': [{'word': "we're", 'start': 0.7, 'end': 0.9}]},
            {'words': [{'word': 'going', 'start': 0.9, 'end': 1.1}]},
            # ... many more words, but 'targeting' will be missing
        ]
    }
    
    # For this test, let's create a more complete word list but skip 'targeting'
    text_words = whisper_result['text'].split()
    chunks = []
    current_time = 0.0
    
    for word in text_words:
        # Skip 'targeting' to simulate Whisper bug
        if word.lower() == 'targeting':
            continue
        
        chunks.append({
            'words': [{
                'word': word,
                'start': current_time,
                'end': current_time + 0.4
            }]
        })
        current_time += 0.4
    
    whisper_result['chunks'] = chunks
    
    print("\n" + "="*80)
    print("COMPLETE PIPELINE TEST")
    print("="*80)
    
    # Process through worker
    worker = HighPerformanceBatchWorker()
    words = worker.extract_words_from_result(whisper_result)
    
    print(f"\n‚úÖ Extracted {len(words)} words")
    
    # Check for 'targeting'
    word_list = [w['word'].lower().strip('.,!?";:') for w in words]
    
    if 'targeting' in word_list:
        print(f"‚úÖ 'targeting' found in extracted words!")
    else:
        print(f"‚ùå 'targeting' MISSING from extracted words!")
        return False
    
    # Create segments
    segments = OptimizedSubtitleFormatter.create_optimized_segments(words, max_chars=84)
    
    print(f"‚úÖ Created {len(segments)} segments")
    
    # Create VTT
    vtt = OptimizedSubtitleFormatter.create_vtt_optimized(segments, max_chars_per_line=42)
    
    # Check VTT
    if 'targeting' in vtt.lower():
        print(f"‚úÖ 'targeting' found in VTT output!")
    else:
        print(f"‚ùå 'targeting' MISSING from VTT output!")
        return False
    
    # Show sample VTT
    vtt_lines = vtt.split('\n')
    print(f"\nüìÑ Sample VTT output (first 20 lines):")
    for line in vtt_lines[:20]:
        print(f"   {line}")
    
    print("\n" + "="*80)
    print("‚úÖ COMPLETE PIPELINE TEST PASSED!")
    print("="*80)
    
    return True


if __name__ == '__main__':
    success = test_complete_pipeline()
    if success:
        print("\nüéâ All systems go! Your captioner will now preserve all words!")
    else:
        print("\n‚ùå Test failed - there's still an issue")
