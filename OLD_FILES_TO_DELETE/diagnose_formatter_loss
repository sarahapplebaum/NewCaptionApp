"""
Test with realistic full-length transcript to see where words are lost
"""

from captioner import OptimizedSubtitleFormatter

def test_with_full_transcript():
    """Test with the actual full transcript"""
    
    # Your actual transcript
    raw_text = """In this video, we're going to go over screen space reflections, which is a complex topic that deserves a little bit more time for discussion. Screen space reflections allow you to calculate reflections from the scene in real time without needing to use reflection probes, which we cover in the next module. This is a very intense effect, so reflection probes are the more performant option, but screen space reflections are an option if you're targeting very high-end devices. You're going to see this effect mostly on water, metallics, and other reflective materials. Once we've added screen space reflections onto our volume, let's take a look at it in action. Right now in our evening A scene here, the main thing that uses reflections are these air ducts above us. If I were to disable these reflection probes, we can see the color of these air ducts completely change, since after all these ducts are metallic and they reflect the light from the office around it. These reflection probes approximate the amount of light that the metallic air ducts are going to give off. Let's say I want to completely do away with reflection probes and have these use screen space reflections to approximate their reflection. What we can do is we can come over to the material that these air ducts use. So for example, if I select this and I can see that that the in the materials is air ducts B, I can go ahead and select air ducts B, toggle receive SSR, and I can do the same with these materials as well. Enable SSR on all of these air duct materials and now if I go into my volume here and I start messing around with the screen space reflection settings I can start getting these air ducts to reflect light using the scene itself rather than reflection probes. We can change the amount of smoothness. Minimum smoothness determines how smooth an object must be for SSR to be applied. Objects below this minimum use another reflection method such as probes. The smoothness fade start will set the smoothness value at which SSR reflections begin to fade out. Lower values results in HDRP fading out SSR reflections for less smooth game objects. We have some other settings here such as the ability to reflect the sky, the screen edge fade distance, as well as the object thickness. This controls how thick objects are inside of your scene. So if I set this thickness to one, we'll see more reflections on our ducks here because the rays are not passing through them as much. Additionally, we also have some quality settings here. So I can set this to high quality to get a bit of a better reflection. And we can also change the algorithm as well, from approximation to PBR accumulation. Approximation is a quicker algorithm, which results in less resources used, but it's not as accurate for rough surfaces. Something like PBR accumulation accumulates multiple frames to generate a more accurate result. And we can control the amount of accumulation using this accumulation factor. This gives a more accurate result, but it is resource intensive, and it can lead to some ghosting. Additionally, this algorithm cannot be used on transparent materials, as those will always use approximation. In the next module, we'll begin talking about the basics of lighting inside of HDRP by learning about the different light types."""
    
    words_list = raw_text.split()
    
    print("\n" + "="*80)
    print("TESTING WITH FULL TRANSCRIPT (575 words)")
    print("="*80)
    
    # Create word list
    words = []
    current_time = 0.0
    for word in words_list:
        words.append({
            "word": word,
            "start": current_time,
            "end": current_time + 0.4
        })
        current_time += 0.4
    
    print(f"\nüì• Input: {len(words)} words")
    
    # Critical words to track
    critical_words = ['targeting', 'metallic', 'as', 'more', 'resource']
    
    print(f"\nüîç Critical words in input:")
    for critical in critical_words:
        count = sum(1 for w in words_list if w.lower() == critical.lower())
        print(f"   '{critical}': {count} occurrences")
    
    # Test clean_and_process_words
    print(f"\n" + "="*80)
    print("STEP 1: Testing clean_and_process_words")
    print("="*80)
    
    cleaned = OptimizedSubtitleFormatter.clean_and_process_words(words)
    cleaned_words = [w.word for w in cleaned]
    
    print(f"\nüì§ Output: {len(cleaned)} words")
    
    print(f"\nüîç Critical words after cleaning:")
    for critical in critical_words:
        count = sum(1 for w in cleaned_words if w.lower() == critical.lower())
        input_count = sum(1 for w in words_list if w.lower() == critical.lower())
        if count < input_count:
            print(f"   ‚ùå '{critical}': {count}/{input_count} (LOST {input_count - count})")
        elif count == input_count:
            print(f"   ‚úÖ '{critical}': {count}/{input_count}")
        else:
            print(f"   ‚ö†Ô∏è  '{critical}': {count}/{input_count} (EXTRA)")
    
    # Test create_optimized_segments
    print(f"\n" + "="*80)
    print("STEP 2: Testing create_optimized_segments")
    print("="*80)
    
    segments = OptimizedSubtitleFormatter.create_optimized_segments(words)
    
    print(f"\nüì¶ Created {len(segments)} segments")
    
    # Extract all words from segments
    segment_text = ' '.join([seg.get('text', '') for seg in segments])
    segment_words = segment_text.split()
    segment_words_clean = [w.lower().strip('.,!?";:\'"') for w in segment_words]
    
    print(f"üìù Total words in segments: {len(segment_words)}")
    
    print(f"\nüîç Critical words in final segments:")
    for critical in critical_words:
        count = sum(1 for w in segment_words_clean if w == critical.lower())
        input_count = sum(1 for w in words_list if w.lower() == critical.lower())
        if count < input_count:
            print(f"   ‚ùå '{critical}': {count}/{input_count} (LOST {input_count - count})")
            
            # Find where it should be
            for i, word in enumerate(words_list):
                if word.lower() == critical.lower():
                    context_start = max(0, i - 3)
                    context_end = min(len(words_list), i + 4)
                    context = ' '.join(words_list[context_start:context_end])
                    print(f"      Expected context: ...{context}...")
                    break
        elif count == input_count:
            print(f"   ‚úÖ '{critical}': {count}/{input_count}")
        else:
            print(f"   ‚ö†Ô∏è  '{critical}': {count}/{input_count} (EXTRA)")
    
    # Show sample segments where words should be
    print(f"\nüìÑ Segments around 'targeting' position:")
    for i, seg in enumerate(segments):
        text = seg.get('text', '')
        if 'very high-end' in text.lower() or 'high-end devices' in text.lower():
            print(f"   [{i}] {text}")
    
    print(f"\nüìÑ Segments around 'metallic' position:")
    for i, seg in enumerate(segments):
        text = seg.get('text', '')
        if 'ducts are' in text.lower() or 'metallic' in text.lower():
            print(f"   [{i}] {text}")
    
    print("\n" + "="*80)


if __name__ == '__main__':
    test_with_full_transcript()
