"""
Inspect actual Whisper output to see what words are provided
This will show us if Whisper is skipping words or if we're losing them in extraction
"""

import json
from typing import Dict, List


def simulate_whisper_output_inspection():
    """
    Simulate inspecting Whisper's output structure
    Show what we should be checking
    """
    
    print("\n" + "="*80)
    print("WHISPER OUTPUT INSPECTION GUIDE")
    print("="*80)
    
    print("""
When Whisper returns results with word-level timestamps, the structure is:

{
    "text": "Full transcript text here...",
    "chunks": [
        {
            "timestamp": [start, end],
            "text": "chunk text",
            "words": [
                {"word": " word1", "start": 0.0, "end": 0.5},
                {"word": " word2", "start": 0.5, "end": 1.0}
            ]
        }
    ]
}

OR sometimes:

{
    "text": "Full transcript text",
    "chunks": [
        {"timestamp": [start, end], "text": "word1"},
        {"timestamp": [start, end], "text": "word2"}
    ]
}

COMMON ISSUES:
1. Some words appear in 'text' but not in 'chunks'/'words'
2. Words with punctuation might be split oddly
3. Short words like "as", "a", "I" sometimes get skipped in word timestamps
4. Whisper might merge words like "you're" or split hyphenated words
""")


def check_word_in_full_text_vs_words():
    """
    Check if Whisper's full text contains words that aren't in word-level output
    """
    
    print("\n" + "="*80)
    print("CHECKING: Full text vs word-level timestamps")
    print("="*80)
    
    # Simulate what Whisper might return
    whisper_full_text = "if you're targeting very high-end devices"
    
    # Whisper might give us word-level like this:
    whisper_words = [
        {"word": "if", "start": 0.0, "end": 0.2},
        {"word": "you're", "start": 0.2, "end": 0.6},
        # "targeting" might be missing here!
        {"word": "very", "start": 1.0, "end": 1.3},
        {"word": "high-end", "start": 1.3, "end": 1.8},
        {"word": "devices", "start": 1.8, "end": 2.2}
    ]
    
    print(f"\nWhisper full text: {whisper_full_text}")
    print(f"Words in full text: {whisper_full_text.split()}")
    print(f"\nWhisper word-level timestamps: {len(whisper_words)} words")
    for w in whisper_words:
        print(f"  {w['word']}")
    
    # Find missing
    full_text_words = set(whisper_full_text.lower().split())
    timestamp_words = set(w['word'].strip().lower() for w in whisper_words)
    
    missing = full_text_words - timestamp_words
    
    print(f"\nâŒ Words in full text but NOT in word timestamps: {missing}")
    print("""
This is the problem! Whisper gives us:
- result['text']: Full transcript (complete)
- result['chunks']: Word-level timestamps (INCOMPLETE - missing some words)

Solution: We need to handle missing word timestamps!
""")


def propose_solution():
    """
    Propose solution for handling missing words
    """
    
    print("\n" + "="*80)
    print("PROPOSED SOLUTION")
    print("="*80)
    
    print("""
OPTION 1: Detect and Insert Missing Words
------------------------------------------
1. Extract words from result['text']
2. Extract words from result['chunks']/word-level
3. Find words in text that aren't in word-level
4. Insert them with estimated timestamps

OPTION 2: Use Full Text When Word-Level is Incomplete  
------------------------------------------------------
1. Compare word count in text vs word-level
2. If significant mismatch (>5% difference), fall back to text-only
3. Create segments from full text with estimated timing

OPTION 3: Hybrid Approach (RECOMMENDED)
----------------------------------------
1. Use word-level timestamps where available
2. For missing words, estimate position based on surrounding timestamps
3. Merge both sources intelligently

Example code for Option 3:

def reconcile_words_with_text(result):
    '''Merge full text with word-level timestamps'''
    
    full_text_words = result['text'].split()
    word_level = extract_word_level_timestamps(result)
    word_level_words = [w['word'].strip() for w in word_level]
    
    # Find missing words
    reconciled = []
    full_idx = 0
    word_idx = 0
    
    while full_idx < len(full_text_words):
        expected_word = full_text_words[full_idx].lower()
        
        if word_idx < len(word_level):
            actual_word = word_level_words[word_idx].lower().strip()
            
            if expected_word == actual_word:
                # Match! Use word-level timestamp
                reconciled.append(word_level[word_idx])
                full_idx += 1
                word_idx += 1
            else:
                # Missing word! Estimate timestamp
                if reconciled:
                    last_end = reconciled[-1]['end']
                    estimated_start = last_end
                    estimated_end = last_end + 0.3
                else:
                    estimated_start = 0.0
                    estimated_end = 0.3
                
                reconciled.append({
                    'word': full_text_words[full_idx],
                    'start': estimated_start,
                    'end': estimated_end,
                    'estimated': True  # Flag it
                })
                full_idx += 1
        else:
            # No more word-level data, estimate rest
            if reconciled:
                last_end = reconciled[-1]['end']
            else:
                last_end = 0.0
            
            reconciled.append({
                'word': full_text_words[full_idx],
                'start': last_end,
                'end': last_end + 0.3,
                'estimated': True
            })
            full_idx += 1
    
    return reconciled
""")


def create_fix_for_batch_worker():
    """
    Show the exact fix needed in HighPerformanceBatchWorker
    """
    
    print("\n" + "="*80)
    print("FIX FOR HighPerformanceBatchWorker.extract_words_from_result()")
    print("="*80)
    
    print("""
Current extract_words_from_result() only extracts word-level timestamps.
We need to add reconciliation with full text.

ADD THIS METHOD to HighPerformanceBatchWorker:

@staticmethod
def reconcile_missing_words(result: Dict) -> List[Dict]:
    '''Reconcile full text with word-level timestamps to find missing words'''
    
    # Get full text
    full_text = result.get('text', '').strip()
    if not full_text:
        return []
    
    full_text_words = full_text.split()
    
    # Get word-level timestamps
    word_level = []
    try:
        if 'chunks' in result:
            for chunk in result['chunks']:
                if isinstance(chunk, dict) and 'words' in chunk:
                    chunk_words = chunk['words']
                    if isinstance(chunk_words, list):
                        word_level.extend(chunk_words)
                elif isinstance(chunk, dict) and 'timestamp' in chunk:
                    timestamp = chunk['timestamp']
                    if isinstance(timestamp, (list, tuple)) and len(timestamp) >= 2:
                        word_level.append({
                            'word': chunk.get('text', ''),
                            'start': safe_float(timestamp[0], 0.0),
                            'end': safe_float(timestamp[1], 0.0)
                        })
        elif 'words' in result:
            word_level = result['words']
    except Exception as e:
        logger.warning(f"Error extracting word level: {e}")
    
    # Clean word-level words for comparison
    word_level_words = [w.get('word', '').strip().lower() for w in word_level]
    
    # Reconcile
    reconciled = []
    word_level_idx = 0
    
    for i, expected_word in enumerate(full_text_words):
        expected_normalized = expected_word.lower().strip('.,!?";:\\'')
        
        # Try to find this word in word_level
        found = False
        
        if word_level_idx < len(word_level):
            actual_normalized = word_level_words[word_level_idx].strip('.,!?";:\\'')
            
            if expected_normalized == actual_normalized:
                # Found it!
                reconciled.append(word_level[word_level_idx])
                word_level_idx += 1
                found = True
            else:
                # Try next few words (in case of mismatch)
                for offset in range(1, min(5, len(word_level) - word_level_idx)):
                    check_word = word_level_words[word_level_idx + offset].strip('.,!?";:\\'')
                    if expected_normalized == check_word:
                        # Found it ahead, insert estimated timestamps for skipped words
                        for skip_idx in range(word_level_idx, word_level_idx + offset):
                            if reconciled:
                                last_end = safe_float(reconciled[-1].get('end'), 0)
                                estimated_start = last_end
                                estimated_end = last_end + 0.3
                            else:
                                estimated_start = i * 0.3
                                estimated_end = (i + 1) * 0.3
                            
                            reconciled.append({
                                'word': word_level[skip_idx].get('word', ''),
                                'start': estimated_start,
                                'end': estimated_end
                            })
                        
                        # Now add the found word
                        reconciled.append(word_level[word_level_idx + offset])
                        word_level_idx += offset + 1
                        found = True
                        break
        
        if not found:
            # Word not in word_level, estimate it
            if reconciled:
                last_end = safe_float(reconciled[-1].get('end'), 0)
                estimated_start = last_end
                estimated_end = last_end + 0.3
            else:
                estimated_start = i * 0.3
                estimated_end = (i + 1) * 0.3
            
            reconciled.append({
                'word': expected_word,
                'start': estimated_start,
                'end': estimated_end
            })
            
            logger.info(f"Estimated timestamp for missing word: '{expected_word}'")
    
    return reconciled


Then MODIFY extract_words_from_result() to use it:

@staticmethod
def extract_words_from_result(result: Dict) -> List[Dict]:
    '''Extract word-level timestamps with reconciliation for missing words'''
    
    # Try reconciliation first
    try:
        reconciled = HighPerformanceBatchWorker.reconcile_missing_words(result)
        if reconciled:
            logger.info(f"Reconciled {len(reconciled)} words")
            return reconciled
    except Exception as e:
        logger.warning(f"Reconciliation failed: {e}, falling back to basic extraction")
    
    # Fallback to original method
    words = []
    # ... existing extraction code ...
    return words
""")


if __name__ == '__main__':
    simulate_whisper_output_inspection()
    check_word_in_full_text_vs_words()
    propose_solution()
    create_fix_for_batch_worker()
    
    print("\n" + "="*80)
    print("SUMMARY")
    print("="*80)
    print("""
The issue is NOT in OptimizedSubtitleFormatter.
The issue is that Whisper's word-level timestamps are incomplete.

Whisper returns:
- result['text']: "...if you're targeting very high-end devices..." (COMPLETE)
- result['chunks']: Word timestamps missing 'targeting', 'metallic', 'as' (INCOMPLETE)

Solution: Reconcile full text with word-level timestamps, estimating
timestamps for missing words based on surrounding context.

Next step: Implement reconcile_missing_words() in the batch worker.
""")
